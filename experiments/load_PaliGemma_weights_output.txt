(pi-zero-pytorch) Mac:pi-zero-pytorch ramkumarkoppu$ python load_pretrained_PaliGemma_weights.py 
Using device: mps
Pretrained weights loaded.
Keys in pretrained weights:
dict_keys(['language_model.model.embed_tokens.weight', 'language_model.model.layers.0.input_layernorm.weight', 'language_model.model.layers.0.mlp.down_proj.weight', 'language_model.model.layers.0.mlp.gate_proj.weight', 'language_model.model.layers.0.mlp.up_proj.weight', 'language_model.model.layers.0.post_attention_layernorm.weight', 'language_model.model.layers.0.self_attn.k_proj.weight', 'language_model.model.layers.0.self_attn.o_proj.weight', 'language_model.model.layers.0.self_attn.q_proj.weight', 'language_model.model.layers.0.self_attn.v_proj.weight', 'language_model.model.layers.1.input_layernorm.weight', 'language_model.model.layers.1.mlp.down_proj.weight', 'language_model.model.layers.1.mlp.gate_proj.weight', 'language_model.model.layers.1.mlp.up_proj.weight', 'language_model.model.layers.1.post_attention_layernorm.weight', 'language_model.model.layers.1.self_attn.k_proj.weight', 'language_model.model.layers.1.self_attn.o_proj.weight', 'language_model.model.layers.1.self_attn.q_proj.weight', 'language_model.model.layers.1.self_attn.v_proj.weight', 'language_model.model.layers.2.mlp.gate_proj.weight', 'language_model.model.layers.2.mlp.up_proj.weight', 'language_model.model.layers.2.self_attn.k_proj.weight', 'language_model.model.layers.2.self_attn.o_proj.weight', 'language_model.model.layers.2.self_attn.q_proj.weight', 'language_model.model.layers.2.self_attn.v_proj.weight', 'multi_modal_projector.linear.bias', 'multi_modal_projector.linear.weight', 'vision_tower.vision_model.embeddings.patch_embedding.bias', 'vision_tower.vision_model.embeddings.patch_embedding.weight', 'vision_tower.vision_model.embeddings.position_embedding.weight', 'vision_tower.vision_model.encoder.layers.0.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.0.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.0.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.0.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.0.mlp.fc1.bias', 'vision_tower.vision_model.encoder.layers.0.mlp.fc1.weight', 'vision_tower.vision_model.encoder.layers.0.mlp.fc2.bias', 'vision_tower.vision_model.encoder.layers.0.mlp.fc2.weight', 'vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.bias', 'vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.weight', 'vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.bias', 'vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.weight', 'vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.bias', 'vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.weight', 'vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.bias', 'vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.weight', 'vision_tower.vision_model.encoder.layers.1.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.1.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.1.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.1.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.1.mlp.fc1.bias', 'vision_tower.vision_model.encoder.layers.1.mlp.fc1.weight', 'vision_tower.vision_model.encoder.layers.1.mlp.fc2.bias', 'vision_tower.vision_model.encoder.layers.1.mlp.fc2.weight', 'vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.bias', 'vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.weight', 'vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.bias', 'vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.weight', 'vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.bias', 'vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.weight', 'vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.bias', 'vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.weight', 'vision_tower.vision_model.encoder.layers.10.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.10.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.10.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.10.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.10.mlp.fc1.bias', 'vision_tower.vision_model.encoder.layers.10.mlp.fc1.weight', 'vision_tower.vision_model.encoder.layers.10.mlp.fc2.bias', 'vision_tower.vision_model.encoder.layers.10.mlp.fc2.weight', 'vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.bias', 'vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.weight', 'vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.bias', 'vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.weight', 'vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.bias', 'vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.weight', 'vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.bias', 'vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.weight', 'vision_tower.vision_model.encoder.layers.11.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.11.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.11.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.11.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.11.mlp.fc1.bias', 'vision_tower.vision_model.encoder.layers.11.mlp.fc1.weight', 'vision_tower.vision_model.encoder.layers.11.mlp.fc2.bias', 'vision_tower.vision_model.encoder.layers.11.mlp.fc2.weight', 'vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.bias', 'vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.weight', 'vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.bias', 'vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.weight', 'vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.bias', 'vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.weight', 'vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.bias', 'vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.weight', 'vision_tower.vision_model.encoder.layers.12.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.12.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.12.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.12.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.12.mlp.fc1.bias', 'vision_tower.vision_model.encoder.layers.12.mlp.fc1.weight', 'vision_tower.vision_model.encoder.layers.12.mlp.fc2.bias', 'vision_tower.vision_model.encoder.layers.12.mlp.fc2.weight', 'vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.bias', 'vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.weight', 'vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.bias', 'vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.weight', 'vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.bias', 'vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.weight', 'vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.bias', 'vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.weight', 'vision_tower.vision_model.encoder.layers.13.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.13.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.13.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.13.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.13.mlp.fc1.bias', 'vision_tower.vision_model.encoder.layers.13.mlp.fc1.weight', 'vision_tower.vision_model.encoder.layers.13.mlp.fc2.bias', 'vision_tower.vision_model.encoder.layers.13.mlp.fc2.weight', 'vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.bias', 'vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.weight', 'vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.bias', 'vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.weight', 'vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.bias', 'vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.weight', 'vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.bias', 'vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.weight', 'vision_tower.vision_model.encoder.layers.14.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.14.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.14.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.14.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.14.mlp.fc1.bias', 'vision_tower.vision_model.encoder.layers.14.mlp.fc1.weight', 'vision_tower.vision_model.encoder.layers.14.mlp.fc2.bias', 'vision_tower.vision_model.encoder.layers.14.mlp.fc2.weight', 'vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.bias', 'vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.weight', 'vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.bias', 'vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.weight', 'vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.bias', 'vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.weight', 'vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.bias', 'vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.weight', 'vision_tower.vision_model.encoder.layers.15.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.15.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.15.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.15.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.15.mlp.fc1.bias', 'vision_tower.vision_model.encoder.layers.15.mlp.fc1.weight', 'vision_tower.vision_model.encoder.layers.15.mlp.fc2.bias', 'vision_tower.vision_model.encoder.layers.15.mlp.fc2.weight', 'vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.bias', 'vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.weight', 'vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.bias', 'vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.weight', 'vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.bias', 'vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.weight', 'vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.bias', 'vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.weight', 'vision_tower.vision_model.encoder.layers.16.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.16.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.16.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.16.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.16.mlp.fc1.bias', 'vision_tower.vision_model.encoder.layers.16.mlp.fc1.weight', 'vision_tower.vision_model.encoder.layers.16.mlp.fc2.bias', 'vision_tower.vision_model.encoder.layers.16.mlp.fc2.weight', 'vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.bias', 'vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.weight', 'vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.bias', 'vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.weight', 'vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.bias', 'vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.weight', 'vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.bias', 'vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.weight', 'vision_tower.vision_model.encoder.layers.17.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.17.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.17.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.17.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.17.mlp.fc1.bias', 'vision_tower.vision_model.encoder.layers.17.mlp.fc1.weight', 'vision_tower.vision_model.encoder.layers.17.mlp.fc2.bias', 'vision_tower.vision_model.encoder.layers.17.mlp.fc2.weight', 'vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.bias', 'vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.weight', 'vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.bias', 'vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.weight', 'vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.bias', 'vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.weight', 'vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.bias', 'vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.weight', 'vision_tower.vision_model.encoder.layers.18.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.18.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.18.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.18.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.18.mlp.fc1.bias', 'vision_tower.vision_model.encoder.layers.18.mlp.fc1.weight', 'vision_tower.vision_model.encoder.layers.18.mlp.fc2.bias', 'vision_tower.vision_model.encoder.layers.18.mlp.fc2.weight', 'vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.bias', 'vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.weight', 'vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.bias', 'vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.weight', 'vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.bias', 'vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.weight', 'vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.bias', 'vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.weight', 'vision_tower.vision_model.encoder.layers.19.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.19.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.19.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.19.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.19.mlp.fc1.bias', 'vision_tower.vision_model.encoder.layers.19.mlp.fc1.weight', 'vision_tower.vision_model.encoder.layers.19.mlp.fc2.bias', 'vision_tower.vision_model.encoder.layers.19.mlp.fc2.weight', 'vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.bias', 'vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.weight', 'vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.bias', 'vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.weight', 'vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.bias', 'vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.weight', 'vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.bias', 'vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.weight', 'vision_tower.vision_model.encoder.layers.2.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.2.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.2.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.2.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.2.mlp.fc1.bias', 'vision_tower.vision_model.encoder.layers.2.mlp.fc1.weight', 'vision_tower.vision_model.encoder.layers.2.mlp.fc2.bias', 'vision_tower.vision_model.encoder.layers.2.mlp.fc2.weight', 'vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.bias', 'vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.weight', 'vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.bias', 'vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.weight', 'vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.bias', 'vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.weight', 'vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.bias', 'vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.weight', 'vision_tower.vision_model.encoder.layers.20.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.20.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.20.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.20.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.20.mlp.fc1.bias', 'vision_tower.vision_model.encoder.layers.20.mlp.fc1.weight', 'vision_tower.vision_model.encoder.layers.20.mlp.fc2.bias', 'vision_tower.vision_model.encoder.layers.20.mlp.fc2.weight', 'vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.bias', 'vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.weight', 'vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.bias', 'vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.weight', 'vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.bias', 'vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.weight', 'vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.bias', 'vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.weight', 'vision_tower.vision_model.encoder.layers.21.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.21.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.21.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.21.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.21.mlp.fc1.bias', 'vision_tower.vision_model.encoder.layers.21.mlp.fc1.weight', 'vision_tower.vision_model.encoder.layers.21.mlp.fc2.bias', 'vision_tower.vision_model.encoder.layers.21.mlp.fc2.weight', 'vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.bias', 'vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.weight', 'vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.bias', 'vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.weight', 'vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.bias', 'vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.weight', 'vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.bias', 'vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.weight', 'vision_tower.vision_model.encoder.layers.22.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.22.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.22.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.22.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.22.mlp.fc1.bias', 'vision_tower.vision_model.encoder.layers.22.mlp.fc1.weight', 'vision_tower.vision_model.encoder.layers.22.mlp.fc2.bias', 'vision_tower.vision_model.encoder.layers.22.mlp.fc2.weight', 'vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.bias', 'vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.weight', 'vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.bias', 'vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.weight', 'vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.bias', 'vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.weight', 'vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.bias', 'vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.weight', 'vision_tower.vision_model.encoder.layers.23.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.23.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.23.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.23.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.23.mlp.fc1.bias', 'vision_tower.vision_model.encoder.layers.23.mlp.fc1.weight', 'vision_tower.vision_model.encoder.layers.23.mlp.fc2.bias', 'vision_tower.vision_model.encoder.layers.23.mlp.fc2.weight', 'vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.bias', 'vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.weight', 'vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.bias', 'vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.weight', 'vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.bias', 'vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.weight', 'vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.bias', 'vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.weight', 'vision_tower.vision_model.encoder.layers.24.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.24.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.24.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.24.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.24.mlp.fc1.bias', 'vision_tower.vision_model.encoder.layers.24.mlp.fc1.weight', 'vision_tower.vision_model.encoder.layers.24.mlp.fc2.bias', 'vision_tower.vision_model.encoder.layers.24.mlp.fc2.weight', 'vision_tower.vision_model.encoder.layers.24.self_attn.k_proj.bias', 'vision_tower.vision_model.encoder.layers.24.self_attn.k_proj.weight', 'vision_tower.vision_model.encoder.layers.24.self_attn.out_proj.bias', 'vision_tower.vision_model.encoder.layers.24.self_attn.out_proj.weight', 'vision_tower.vision_model.encoder.layers.24.self_attn.q_proj.bias', 'vision_tower.vision_model.encoder.layers.24.self_attn.q_proj.weight', 'vision_tower.vision_model.encoder.layers.24.self_attn.v_proj.bias', 'vision_tower.vision_model.encoder.layers.24.self_attn.v_proj.weight', 'vision_tower.vision_model.encoder.layers.25.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.25.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.25.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.25.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.25.mlp.fc1.bias', 'vision_tower.vision_model.encoder.layers.25.mlp.fc1.weight', 'vision_tower.vision_model.encoder.layers.25.mlp.fc2.bias', 'vision_tower.vision_model.encoder.layers.25.mlp.fc2.weight', 'vision_tower.vision_model.encoder.layers.25.self_attn.k_proj.bias', 'vision_tower.vision_model.encoder.layers.25.self_attn.k_proj.weight', 'vision_tower.vision_model.encoder.layers.25.self_attn.out_proj.bias', 'vision_tower.vision_model.encoder.layers.25.self_attn.out_proj.weight', 'vision_tower.vision_model.encoder.layers.25.self_attn.q_proj.bias', 'vision_tower.vision_model.encoder.layers.25.self_attn.q_proj.weight', 'vision_tower.vision_model.encoder.layers.25.self_attn.v_proj.bias', 'vision_tower.vision_model.encoder.layers.25.self_attn.v_proj.weight', 'vision_tower.vision_model.encoder.layers.26.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.26.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.26.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.26.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.26.mlp.fc1.bias', 'vision_tower.vision_model.encoder.layers.26.mlp.fc1.weight', 'vision_tower.vision_model.encoder.layers.26.mlp.fc2.bias', 'vision_tower.vision_model.encoder.layers.26.mlp.fc2.weight', 'vision_tower.vision_model.encoder.layers.26.self_attn.k_proj.bias', 'vision_tower.vision_model.encoder.layers.26.self_attn.k_proj.weight', 'vision_tower.vision_model.encoder.layers.26.self_attn.out_proj.bias', 'vision_tower.vision_model.encoder.layers.26.self_attn.out_proj.weight', 'vision_tower.vision_model.encoder.layers.26.self_attn.q_proj.bias', 'vision_tower.vision_model.encoder.layers.26.self_attn.q_proj.weight', 'vision_tower.vision_model.encoder.layers.26.self_attn.v_proj.bias', 'vision_tower.vision_model.encoder.layers.26.self_attn.v_proj.weight', 'vision_tower.vision_model.encoder.layers.3.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.3.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.3.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.3.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.3.mlp.fc1.bias', 'vision_tower.vision_model.encoder.layers.3.mlp.fc1.weight', 'vision_tower.vision_model.encoder.layers.3.mlp.fc2.bias', 'vision_tower.vision_model.encoder.layers.3.mlp.fc2.weight', 'vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.bias', 'vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.weight', 'vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.bias', 'vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.weight', 'vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.bias', 'vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.weight', 'vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.bias', 'vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.weight', 'vision_tower.vision_model.encoder.layers.4.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.4.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.4.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.4.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.4.mlp.fc1.bias', 'vision_tower.vision_model.encoder.layers.4.mlp.fc1.weight', 'vision_tower.vision_model.encoder.layers.4.mlp.fc2.bias', 'vision_tower.vision_model.encoder.layers.4.mlp.fc2.weight', 'vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.bias', 'vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.weight', 'vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.bias', 'vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.weight', 'vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.bias', 'vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.weight', 'vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.bias', 'vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.weight', 'vision_tower.vision_model.encoder.layers.5.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.5.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.5.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.5.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.5.mlp.fc1.bias', 'vision_tower.vision_model.encoder.layers.5.mlp.fc1.weight', 'vision_tower.vision_model.encoder.layers.5.mlp.fc2.bias', 'vision_tower.vision_model.encoder.layers.5.mlp.fc2.weight', 'vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.bias', 'vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.weight', 'vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.bias', 'vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.weight', 'vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.bias', 'vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.weight', 'vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.bias', 'vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.weight', 'vision_tower.vision_model.encoder.layers.6.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.6.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.6.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.6.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.6.mlp.fc1.bias', 'vision_tower.vision_model.encoder.layers.6.mlp.fc1.weight', 'vision_tower.vision_model.encoder.layers.6.mlp.fc2.bias', 'vision_tower.vision_model.encoder.layers.6.mlp.fc2.weight', 'vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.bias', 'vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.weight', 'vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.bias', 'vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.weight', 'vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.bias', 'vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.weight', 'vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.bias', 'vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.weight', 'vision_tower.vision_model.encoder.layers.7.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.7.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.7.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.7.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.7.mlp.fc1.bias', 'vision_tower.vision_model.encoder.layers.7.mlp.fc1.weight', 'vision_tower.vision_model.encoder.layers.7.mlp.fc2.bias', 'vision_tower.vision_model.encoder.layers.7.mlp.fc2.weight', 'vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.bias', 'vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.weight', 'vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.bias', 'vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.weight', 'vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.bias', 'vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.weight', 'vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.bias', 'vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.weight', 'vision_tower.vision_model.encoder.layers.8.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.8.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.8.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.8.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.8.mlp.fc1.bias', 'vision_tower.vision_model.encoder.layers.8.mlp.fc1.weight', 'vision_tower.vision_model.encoder.layers.8.mlp.fc2.bias', 'vision_tower.vision_model.encoder.layers.8.mlp.fc2.weight', 'vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.bias', 'vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.weight', 'vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.bias', 'vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.weight', 'vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.bias', 'vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.weight', 'vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.bias', 'vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.weight', 'vision_tower.vision_model.encoder.layers.9.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.9.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.9.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.9.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.9.mlp.fc1.bias', 'vision_tower.vision_model.encoder.layers.9.mlp.fc1.weight', 'vision_tower.vision_model.encoder.layers.9.mlp.fc2.bias', 'vision_tower.vision_model.encoder.layers.9.mlp.fc2.weight', 'vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.bias', 'vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.weight', 'vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.bias', 'vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.weight', 'vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.bias', 'vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.weight', 'vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.bias', 'vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.weight', 'vision_tower.vision_model.post_layernorm.bias', 'vision_tower.vision_model.post_layernorm.weight', 'language_model.model.layers.10.input_layernorm.weight', 'language_model.model.layers.10.mlp.down_proj.weight', 'language_model.model.layers.10.mlp.gate_proj.weight', 'language_model.model.layers.10.mlp.up_proj.weight', 'language_model.model.layers.10.post_attention_layernorm.weight', 'language_model.model.layers.10.self_attn.k_proj.weight', 'language_model.model.layers.10.self_attn.o_proj.weight', 'language_model.model.layers.10.self_attn.q_proj.weight', 'language_model.model.layers.10.self_attn.v_proj.weight', 'language_model.model.layers.11.input_layernorm.weight', 'language_model.model.layers.11.mlp.down_proj.weight', 'language_model.model.layers.11.mlp.gate_proj.weight', 'language_model.model.layers.11.mlp.up_proj.weight', 'language_model.model.layers.11.post_attention_layernorm.weight', 'language_model.model.layers.11.self_attn.k_proj.weight', 'language_model.model.layers.11.self_attn.o_proj.weight', 'language_model.model.layers.11.self_attn.q_proj.weight', 'language_model.model.layers.11.self_attn.v_proj.weight', 'language_model.model.layers.12.input_layernorm.weight', 'language_model.model.layers.12.mlp.down_proj.weight', 'language_model.model.layers.12.mlp.gate_proj.weight', 'language_model.model.layers.12.mlp.up_proj.weight', 'language_model.model.layers.12.post_attention_layernorm.weight', 'language_model.model.layers.12.self_attn.k_proj.weight', 'language_model.model.layers.12.self_attn.o_proj.weight', 'language_model.model.layers.12.self_attn.q_proj.weight', 'language_model.model.layers.12.self_attn.v_proj.weight', 'language_model.model.layers.13.input_layernorm.weight', 'language_model.model.layers.13.mlp.down_proj.weight', 'language_model.model.layers.13.mlp.gate_proj.weight', 'language_model.model.layers.13.mlp.up_proj.weight', 'language_model.model.layers.13.post_attention_layernorm.weight', 'language_model.model.layers.13.self_attn.k_proj.weight', 'language_model.model.layers.13.self_attn.o_proj.weight', 'language_model.model.layers.13.self_attn.q_proj.weight', 'language_model.model.layers.13.self_attn.v_proj.weight', 'language_model.model.layers.14.self_attn.k_proj.weight', 'language_model.model.layers.14.self_attn.q_proj.weight', 'language_model.model.layers.14.self_attn.v_proj.weight', 'language_model.model.layers.2.input_layernorm.weight', 'language_model.model.layers.2.mlp.down_proj.weight', 'language_model.model.layers.2.post_attention_layernorm.weight', 'language_model.model.layers.3.input_layernorm.weight', 'language_model.model.layers.3.mlp.down_proj.weight', 'language_model.model.layers.3.mlp.gate_proj.weight', 'language_model.model.layers.3.mlp.up_proj.weight', 'language_model.model.layers.3.post_attention_layernorm.weight', 'language_model.model.layers.3.self_attn.k_proj.weight', 'language_model.model.layers.3.self_attn.o_proj.weight', 'language_model.model.layers.3.self_attn.q_proj.weight', 'language_model.model.layers.3.self_attn.v_proj.weight', 'language_model.model.layers.4.input_layernorm.weight', 'language_model.model.layers.4.mlp.down_proj.weight', 'language_model.model.layers.4.mlp.gate_proj.weight', 'language_model.model.layers.4.mlp.up_proj.weight', 'language_model.model.layers.4.post_attention_layernorm.weight', 'language_model.model.layers.4.self_attn.k_proj.weight', 'language_model.model.layers.4.self_attn.o_proj.weight', 'language_model.model.layers.4.self_attn.q_proj.weight', 'language_model.model.layers.4.self_attn.v_proj.weight', 'language_model.model.layers.5.input_layernorm.weight', 'language_model.model.layers.5.mlp.down_proj.weight', 'language_model.model.layers.5.mlp.gate_proj.weight', 'language_model.model.layers.5.mlp.up_proj.weight', 'language_model.model.layers.5.post_attention_layernorm.weight', 'language_model.model.layers.5.self_attn.k_proj.weight', 'language_model.model.layers.5.self_attn.o_proj.weight', 'language_model.model.layers.5.self_attn.q_proj.weight', 'language_model.model.layers.5.self_attn.v_proj.weight', 'language_model.model.layers.6.input_layernorm.weight', 'language_model.model.layers.6.mlp.down_proj.weight', 'language_model.model.layers.6.mlp.gate_proj.weight', 'language_model.model.layers.6.mlp.up_proj.weight', 'language_model.model.layers.6.post_attention_layernorm.weight', 'language_model.model.layers.6.self_attn.k_proj.weight', 'language_model.model.layers.6.self_attn.o_proj.weight', 'language_model.model.layers.6.self_attn.q_proj.weight', 'language_model.model.layers.6.self_attn.v_proj.weight', 'language_model.model.layers.7.input_layernorm.weight', 'language_model.model.layers.7.mlp.down_proj.weight', 'language_model.model.layers.7.mlp.gate_proj.weight', 'language_model.model.layers.7.mlp.up_proj.weight', 'language_model.model.layers.7.post_attention_layernorm.weight', 'language_model.model.layers.7.self_attn.k_proj.weight', 'language_model.model.layers.7.self_attn.o_proj.weight', 'language_model.model.layers.7.self_attn.q_proj.weight', 'language_model.model.layers.7.self_attn.v_proj.weight', 'language_model.model.layers.8.input_layernorm.weight', 'language_model.model.layers.8.mlp.down_proj.weight', 'language_model.model.layers.8.mlp.gate_proj.weight', 'language_model.model.layers.8.mlp.up_proj.weight', 'language_model.model.layers.8.post_attention_layernorm.weight', 'language_model.model.layers.8.self_attn.k_proj.weight', 'language_model.model.layers.8.self_attn.o_proj.weight', 'language_model.model.layers.8.self_attn.q_proj.weight', 'language_model.model.layers.8.self_attn.v_proj.weight', 'language_model.model.layers.9.input_layernorm.weight', 'language_model.model.layers.9.mlp.down_proj.weight', 'language_model.model.layers.9.mlp.gate_proj.weight', 'language_model.model.layers.9.mlp.up_proj.weight', 'language_model.model.layers.9.post_attention_layernorm.weight', 'language_model.model.layers.9.self_attn.k_proj.weight', 'language_model.model.layers.9.self_attn.o_proj.weight', 'language_model.model.layers.9.self_attn.q_proj.weight', 'language_model.model.layers.9.self_attn.v_proj.weight', 'language_model.model.layers.14.input_layernorm.weight', 'language_model.model.layers.14.mlp.down_proj.weight', 'language_model.model.layers.14.mlp.gate_proj.weight', 'language_model.model.layers.14.mlp.up_proj.weight', 'language_model.model.layers.14.post_attention_layernorm.weight', 'language_model.model.layers.14.self_attn.o_proj.weight', 'language_model.model.layers.15.input_layernorm.weight', 'language_model.model.layers.15.mlp.down_proj.weight', 'language_model.model.layers.15.mlp.gate_proj.weight', 'language_model.model.layers.15.mlp.up_proj.weight', 'language_model.model.layers.15.post_attention_layernorm.weight', 'language_model.model.layers.15.self_attn.k_proj.weight', 'language_model.model.layers.15.self_attn.o_proj.weight', 'language_model.model.layers.15.self_attn.q_proj.weight', 'language_model.model.layers.15.self_attn.v_proj.weight', 'language_model.model.layers.16.input_layernorm.weight', 'language_model.model.layers.16.mlp.down_proj.weight', 'language_model.model.layers.16.mlp.gate_proj.weight', 'language_model.model.layers.16.mlp.up_proj.weight', 'language_model.model.layers.16.post_attention_layernorm.weight', 'language_model.model.layers.16.self_attn.k_proj.weight', 'language_model.model.layers.16.self_attn.o_proj.weight', 'language_model.model.layers.16.self_attn.q_proj.weight', 'language_model.model.layers.16.self_attn.v_proj.weight', 'language_model.model.layers.17.input_layernorm.weight', 'language_model.model.layers.17.mlp.down_proj.weight', 'language_model.model.layers.17.mlp.gate_proj.weight', 'language_model.model.layers.17.mlp.up_proj.weight', 'language_model.model.layers.17.post_attention_layernorm.weight', 'language_model.model.layers.17.self_attn.k_proj.weight', 'language_model.model.layers.17.self_attn.o_proj.weight', 'language_model.model.layers.17.self_attn.q_proj.weight', 'language_model.model.layers.17.self_attn.v_proj.weight', 'language_model.model.norm.weight'])
Keys in PiZero model state dict:
odict_keys(['action_register_tokens', 'token_emb.weight', 'to_joint_state_tokens.weight', 'to_joint_state_tokens.bias', 'to_action_tokens.weight', 'to_action_tokens.bias', 'to_time_cond.0.proj.weight', 'to_time_cond.0.proj.bias', 'to_time_cond.1.weight', 'to_time_cond.1.bias', 'rotary_emb.freqs', 'layers.0.0.rmsnorm.weight', 'layers.0.0.to_qkv.weight', 'layers.0.0.to_out.weight', 'layers.0.0.to_actions_qkvg.weight', 'layers.0.0.to_actions_out.weight', 'layers.0.1.rmsnorm.weight', 'layers.0.1.proj_in.weight', 'layers.0.1.proj_out.weight', 'layers.0.2.rmsnorm.weight', 'layers.0.2.proj_in.weight', 'layers.0.2.proj_out.weight', 'layers.1.0.rmsnorm.weight', 'layers.1.0.to_qkv.weight', 'layers.1.0.to_out.weight', 'layers.1.0.to_actions_qkvg.weight', 'layers.1.0.to_actions_out.weight', 'layers.1.1.rmsnorm.weight', 'layers.1.1.proj_in.weight', 'layers.1.1.proj_out.weight', 'layers.1.2.rmsnorm.weight', 'layers.1.2.proj_in.weight', 'layers.1.2.proj_out.weight', 'layers.2.0.rmsnorm.weight', 'layers.2.0.to_qkv.weight', 'layers.2.0.to_out.weight', 'layers.2.0.to_actions_qkvg.weight', 'layers.2.0.to_actions_out.weight', 'layers.2.1.rmsnorm.weight', 'layers.2.1.proj_in.weight', 'layers.2.1.proj_out.weight', 'layers.2.2.rmsnorm.weight', 'layers.2.2.proj_in.weight', 'layers.2.2.proj_out.weight', 'layers.3.0.rmsnorm.weight', 'layers.3.0.to_qkv.weight', 'layers.3.0.to_out.weight', 'layers.3.0.to_actions_qkvg.weight', 'layers.3.0.to_actions_out.weight', 'layers.3.1.rmsnorm.weight', 'layers.3.1.proj_in.weight', 'layers.3.1.proj_out.weight', 'layers.3.2.rmsnorm.weight', 'layers.3.2.proj_in.weight', 'layers.3.2.proj_out.weight', 'layers.4.0.rmsnorm.weight', 'layers.4.0.to_qkv.weight', 'layers.4.0.to_out.weight', 'layers.4.0.to_actions_qkvg.weight', 'layers.4.0.to_actions_out.weight', 'layers.4.1.rmsnorm.weight', 'layers.4.1.proj_in.weight', 'layers.4.1.proj_out.weight', 'layers.4.2.rmsnorm.weight', 'layers.4.2.proj_in.weight', 'layers.4.2.proj_out.weight', 'layers.5.0.rmsnorm.weight', 'layers.5.0.to_qkv.weight', 'layers.5.0.to_out.weight', 'layers.5.0.to_actions_qkvg.weight', 'layers.5.0.to_actions_out.weight', 'layers.5.1.rmsnorm.weight', 'layers.5.1.proj_in.weight', 'layers.5.1.proj_out.weight', 'layers.5.2.rmsnorm.weight', 'layers.5.2.proj_in.weight', 'layers.5.2.proj_out.weight', 'layers.6.0.rmsnorm.weight', 'layers.6.0.to_qkv.weight', 'layers.6.0.to_out.weight', 'layers.6.0.to_actions_qkvg.weight', 'layers.6.0.to_actions_out.weight', 'layers.6.1.rmsnorm.weight', 'layers.6.1.proj_in.weight', 'layers.6.1.proj_out.weight', 'layers.6.2.rmsnorm.weight', 'layers.6.2.proj_in.weight', 'layers.6.2.proj_out.weight', 'layers.7.0.rmsnorm.weight', 'layers.7.0.to_qkv.weight', 'layers.7.0.to_out.weight', 'layers.7.0.to_actions_qkvg.weight', 'layers.7.0.to_actions_out.weight', 'layers.7.1.rmsnorm.weight', 'layers.7.1.proj_in.weight', 'layers.7.1.proj_out.weight', 'layers.7.2.rmsnorm.weight', 'layers.7.2.proj_in.weight', 'layers.7.2.proj_out.weight', 'layers.8.0.rmsnorm.weight', 'layers.8.0.to_qkv.weight', 'layers.8.0.to_out.weight', 'layers.8.0.to_actions_qkvg.weight', 'layers.8.0.to_actions_out.weight', 'layers.8.1.rmsnorm.weight', 'layers.8.1.proj_in.weight', 'layers.8.1.proj_out.weight', 'layers.8.2.rmsnorm.weight', 'layers.8.2.proj_in.weight', 'layers.8.2.proj_out.weight', 'layers.9.0.rmsnorm.weight', 'layers.9.0.to_qkv.weight', 'layers.9.0.to_out.weight', 'layers.9.0.to_actions_qkvg.weight', 'layers.9.0.to_actions_out.weight', 'layers.9.1.rmsnorm.weight', 'layers.9.1.proj_in.weight', 'layers.9.1.proj_out.weight', 'layers.9.2.rmsnorm.weight', 'layers.9.2.proj_in.weight', 'layers.9.2.proj_out.weight', 'layers.10.0.rmsnorm.weight', 'layers.10.0.to_qkv.weight', 'layers.10.0.to_out.weight', 'layers.10.0.to_actions_qkvg.weight', 'layers.10.0.to_actions_out.weight', 'layers.10.1.rmsnorm.weight', 'layers.10.1.proj_in.weight', 'layers.10.1.proj_out.weight', 'layers.10.2.rmsnorm.weight', 'layers.10.2.proj_in.weight', 'layers.10.2.proj_out.weight', 'layers.11.0.rmsnorm.weight', 'layers.11.0.to_qkv.weight', 'layers.11.0.to_out.weight', 'layers.11.0.to_actions_qkvg.weight', 'layers.11.0.to_actions_out.weight', 'layers.11.1.rmsnorm.weight', 'layers.11.1.proj_in.weight', 'layers.11.1.proj_out.weight', 'layers.11.2.rmsnorm.weight', 'layers.11.2.proj_in.weight', 'layers.11.2.proj_out.weight', 'cond_layers.0.0.to_gamma.0.weight', 'cond_layers.0.0.to_gamma.0.bias', 'cond_layers.0.0.to_beta.weight', 'cond_layers.0.1.to_adaln_zero_gamma.weight', 'cond_layers.0.1.to_adaln_zero_gamma.bias', 'cond_layers.0.2.to_gamma.0.weight', 'cond_layers.0.2.to_gamma.0.bias', 'cond_layers.0.2.to_beta.weight', 'cond_layers.0.3.to_adaln_zero_gamma.weight', 'cond_layers.0.3.to_adaln_zero_gamma.bias', 'cond_layers.1.0.to_gamma.0.weight', 'cond_layers.1.0.to_gamma.0.bias', 'cond_layers.1.0.to_beta.weight', 'cond_layers.1.1.to_adaln_zero_gamma.weight', 'cond_layers.1.1.to_adaln_zero_gamma.bias', 'cond_layers.1.2.to_gamma.0.weight', 'cond_layers.1.2.to_gamma.0.bias', 'cond_layers.1.2.to_beta.weight', 'cond_layers.1.3.to_adaln_zero_gamma.weight', 'cond_layers.1.3.to_adaln_zero_gamma.bias', 'cond_layers.2.0.to_gamma.0.weight', 'cond_layers.2.0.to_gamma.0.bias', 'cond_layers.2.0.to_beta.weight', 'cond_layers.2.1.to_adaln_zero_gamma.weight', 'cond_layers.2.1.to_adaln_zero_gamma.bias', 'cond_layers.2.2.to_gamma.0.weight', 'cond_layers.2.2.to_gamma.0.bias', 'cond_layers.2.2.to_beta.weight', 'cond_layers.2.3.to_adaln_zero_gamma.weight', 'cond_layers.2.3.to_adaln_zero_gamma.bias', 'cond_layers.3.0.to_gamma.0.weight', 'cond_layers.3.0.to_gamma.0.bias', 'cond_layers.3.0.to_beta.weight', 'cond_layers.3.1.to_adaln_zero_gamma.weight', 'cond_layers.3.1.to_adaln_zero_gamma.bias', 'cond_layers.3.2.to_gamma.0.weight', 'cond_layers.3.2.to_gamma.0.bias', 'cond_layers.3.2.to_beta.weight', 'cond_layers.3.3.to_adaln_zero_gamma.weight', 'cond_layers.3.3.to_adaln_zero_gamma.bias', 'cond_layers.4.0.to_gamma.0.weight', 'cond_layers.4.0.to_gamma.0.bias', 'cond_layers.4.0.to_beta.weight', 'cond_layers.4.1.to_adaln_zero_gamma.weight', 'cond_layers.4.1.to_adaln_zero_gamma.bias', 'cond_layers.4.2.to_gamma.0.weight', 'cond_layers.4.2.to_gamma.0.bias', 'cond_layers.4.2.to_beta.weight', 'cond_layers.4.3.to_adaln_zero_gamma.weight', 'cond_layers.4.3.to_adaln_zero_gamma.bias', 'cond_layers.5.0.to_gamma.0.weight', 'cond_layers.5.0.to_gamma.0.bias', 'cond_layers.5.0.to_beta.weight', 'cond_layers.5.1.to_adaln_zero_gamma.weight', 'cond_layers.5.1.to_adaln_zero_gamma.bias', 'cond_layers.5.2.to_gamma.0.weight', 'cond_layers.5.2.to_gamma.0.bias', 'cond_layers.5.2.to_beta.weight', 'cond_layers.5.3.to_adaln_zero_gamma.weight', 'cond_layers.5.3.to_adaln_zero_gamma.bias', 'cond_layers.6.0.to_gamma.0.weight', 'cond_layers.6.0.to_gamma.0.bias', 'cond_layers.6.0.to_beta.weight', 'cond_layers.6.1.to_adaln_zero_gamma.weight', 'cond_layers.6.1.to_adaln_zero_gamma.bias', 'cond_layers.6.2.to_gamma.0.weight', 'cond_layers.6.2.to_gamma.0.bias', 'cond_layers.6.2.to_beta.weight', 'cond_layers.6.3.to_adaln_zero_gamma.weight', 'cond_layers.6.3.to_adaln_zero_gamma.bias', 'cond_layers.7.0.to_gamma.0.weight', 'cond_layers.7.0.to_gamma.0.bias', 'cond_layers.7.0.to_beta.weight', 'cond_layers.7.1.to_adaln_zero_gamma.weight', 'cond_layers.7.1.to_adaln_zero_gamma.bias', 'cond_layers.7.2.to_gamma.0.weight', 'cond_layers.7.2.to_gamma.0.bias', 'cond_layers.7.2.to_beta.weight', 'cond_layers.7.3.to_adaln_zero_gamma.weight', 'cond_layers.7.3.to_adaln_zero_gamma.bias', 'cond_layers.8.0.to_gamma.0.weight', 'cond_layers.8.0.to_gamma.0.bias', 'cond_layers.8.0.to_beta.weight', 'cond_layers.8.1.to_adaln_zero_gamma.weight', 'cond_layers.8.1.to_adaln_zero_gamma.bias', 'cond_layers.8.2.to_gamma.0.weight', 'cond_layers.8.2.to_gamma.0.bias', 'cond_layers.8.2.to_beta.weight', 'cond_layers.8.3.to_adaln_zero_gamma.weight', 'cond_layers.8.3.to_adaln_zero_gamma.bias', 'cond_layers.9.0.to_gamma.0.weight', 'cond_layers.9.0.to_gamma.0.bias', 'cond_layers.9.0.to_beta.weight', 'cond_layers.9.1.to_adaln_zero_gamma.weight', 'cond_layers.9.1.to_adaln_zero_gamma.bias', 'cond_layers.9.2.to_gamma.0.weight', 'cond_layers.9.2.to_gamma.0.bias', 'cond_layers.9.2.to_beta.weight', 'cond_layers.9.3.to_adaln_zero_gamma.weight', 'cond_layers.9.3.to_adaln_zero_gamma.bias', 'cond_layers.10.0.to_gamma.0.weight', 'cond_layers.10.0.to_gamma.0.bias', 'cond_layers.10.0.to_beta.weight', 'cond_layers.10.1.to_adaln_zero_gamma.weight', 'cond_layers.10.1.to_adaln_zero_gamma.bias', 'cond_layers.10.2.to_gamma.0.weight', 'cond_layers.10.2.to_gamma.0.bias', 'cond_layers.10.2.to_beta.weight', 'cond_layers.10.3.to_adaln_zero_gamma.weight', 'cond_layers.10.3.to_adaln_zero_gamma.bias', 'cond_layers.11.0.to_gamma.0.weight', 'cond_layers.11.0.to_gamma.0.bias', 'cond_layers.11.0.to_beta.weight', 'cond_layers.11.1.to_adaln_zero_gamma.weight', 'cond_layers.11.1.to_adaln_zero_gamma.bias', 'cond_layers.11.2.to_gamma.0.weight', 'cond_layers.11.2.to_gamma.0.bias', 'cond_layers.11.2.to_beta.weight', 'cond_layers.11.3.to_adaln_zero_gamma.weight', 'cond_layers.11.3.to_adaln_zero_gamma.bias', 'final_norm.weight', 'final_actions_norm.weight', 'state_to_logits.weight', 'actions_to_pred_flow.weight'])
Size mismatch: language_model.model.embed_tokens.weight -> token_emb.weight
Size mismatch: language_model.model.layers.0.self_attn.q_proj.weight -> layers.0.0.to_qkv.weight
Size mismatch: language_model.model.layers.0.self_attn.k_proj.weight -> layers.0.0.to_qkv.weight
Size mismatch: language_model.model.layers.0.self_attn.v_proj.weight -> layers.0.0.to_qkv.weight
Size mismatch: language_model.model.layers.0.self_attn.o_proj.weight -> layers.0.0.to_out.weight
Size mismatch: language_model.model.layers.0.mlp.gate_proj.weight -> layers.0.1.proj_in.weight
Size mismatch: language_model.model.layers.0.mlp.down_proj.weight -> layers.0.1.proj_out.weight
Size mismatch: language_model.model.layers.0.mlp.up_proj.weight -> layers.0.2.proj_out.weight
Size mismatch: language_model.model.norm.weight -> final_norm.weight
Mismatched keys (9): [('language_model.model.embed_tokens.weight', 'token_emb.weight'), ('language_model.model.layers.0.self_attn.q_proj.weight', 'layers.0.0.to_qkv.weight'), ('language_model.model.layers.0.self_attn.k_proj.weight', 'layers.0.0.to_qkv.weight'), ('language_model.model.layers.0.self_attn.v_proj.weight', 'layers.0.0.to_qkv.weight'), ('language_model.model.layers.0.self_attn.o_proj.weight', 'layers.0.0.to_out.weight'), ('language_model.model.layers.0.mlp.gate_proj.weight', 'layers.0.1.proj_in.weight'), ('language_model.model.layers.0.mlp.down_proj.weight', 'layers.0.1.proj_out.weight'), ('language_model.model.layers.0.mlp.up_proj.weight', 'layers.0.2.proj_out.weight'), ('language_model.model.norm.weight', 'final_norm.weight')]
Note: Model loaded in non-strict mode. Missing/mismatched weights ignored.
Weights successfully loaded into the PiZero model.
Updated PiZero model saved as pi_zero_with_paligemma_weights.pth
sampling action trajectory: 34it [00:01, 28.74it/s]                                                                                                       
Sampled actions: tensor([[[-1.4347,  0.9680,  1.5916, -0.3657,  1.6382,  1.0555],
         [ 0.1016,  0.6666,  0.3691, -0.3877,  0.3481,  0.3714],
         [ 0.7162, -1.4007,  0.4000, -0.7159, -0.0431, -0.0826],
         [-0.3358, -0.5231,  0.9695, -0.4180,  0.2119,  0.4315],
         [-1.2667,  1.1501, -0.5204, -0.7984, -0.9955, -0.0452],
         [-0.3422,  0.6332,  0.7908, -0.3584, -1.6254, -0.3940],
         [-0.4916, -0.4470, -0.2109,  1.7990,  0.3284, -0.6485],
         [ 1.2766,  1.0747,  1.5683, -1.4038, -1.4003,  0.2248],
         [ 0.0117,  2.3682,  1.0529,  0.2026,  0.8486, -0.0539],
         [ 1.4434,  0.3645,  1.1324, -2.2518,  0.5924, -1.3285],
         [ 0.9516,  0.4824,  2.9484,  0.1253, -0.3482, -0.3191],
         [ 0.4756,  1.3426,  0.2902, -0.9343,  0.3657,  0.5063],
         [-0.8369,  0.6446,  0.2326, -2.3178,  0.4174,  0.9906],
         [-2.3255, -0.0619,  2.4826,  0.1514,  0.3666, -0.5276],
         [-1.0054,  1.3728,  1.0944, -0.9068,  1.8743, -0.9296],
         [-0.5444, -1.0307,  0.8830,  0.2690,  0.6229, -1.6003],
         [ 0.4129, -0.3498,  1.7275, -0.2669, -0.3091, -1.8377],
         [-0.5722,  1.2714, -0.1753,  0.8035, -0.9159,  0.3575],
         [-0.7905,  0.0712, -0.6845, -2.4967, -0.3601, -0.3088],
         [-1.2568,  1.0018,  1.5000, -0.5968,  0.1524, -0.2441],
         [-0.3490,  0.6797,  0.8638,  0.0465, -1.2568,  0.5091],
         [-0.2006,  1.9666,  2.7092, -2.3882,  0.8620, -0.6097],
         [-1.6341,  3.1883,  0.0960, -0.8813, -0.3028, -0.1709],
         [-1.2643, -0.1921,  1.9740,  0.9418,  0.0079,  0.3614],
         [-0.4052,  1.8378,  3.0374,  1.8566, -0.3673, -2.6973],
         [ 0.2294, -2.3717,  0.4273,  0.0952, -1.7961,  0.1634],
         [ 0.2484,  1.8651,  1.1207, -1.9273, -0.4385, -0.5475],
         [-2.1148,  2.0893,  1.6885, -0.6517,  0.4791, -1.6063],
         [-0.2136,  0.4321,  0.9337, -0.1710,  0.6434, -0.8434],
         [ 0.4900,  2.3985,  1.0797,  0.2760, -0.4225,  0.9200],
         [-0.4876,  1.6132,  0.0221, -0.2874,  0.4356, -1.0799],
         [-1.8361,  2.2421,  1.4594,  0.0725,  0.0924,  0.9358]]],
       device='mps:0')
Type of sampled actions: <class 'torch.Tensor'>
Shape of sampled actions: torch.Size([1, 32, 6])
Time taken: 2 seconds
